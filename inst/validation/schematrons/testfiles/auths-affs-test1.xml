<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" " https://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">

<!--- 
Expected Schematron Errors
  - When there is more than one author and more than one affiliation in a <contrib-group>, there mut be a relationship between them defined by an <xref ref-type="aff" in the <contrib> pointing to the @id on the <aff>.
     
  - Do not put label content in <sup> at the begnning of <aff>. Use <label> instead.
  
  Expected Schematron Warnings
  - Articles should have authors included as <contrib contrib-type="author".
  

-->
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML"
    article-type="other">
    <front>
        <journal-meta>
            <journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
            <journal-id journal-id-type="iso-abbrev">PLoS Biol</journal-id>
            <journal-id journal-id-type="publisher-id">plos</journal-id>
            <journal-id journal-id-type="pmc">plosbiol</journal-id>
            <journal-title-group>
                <journal-title>PLoS Biology</journal-title>
            </journal-title-group>
            <issn pub-type="ppub">1544-9173</issn>
            <issn pub-type="epub">1545-7885</issn>
            <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, CA USA</publisher-loc>
            </publisher>
        </journal-meta>
        <article-meta>
            <article-id pub-id-type="doi">10.1371/journal.pbio.3000188</article-id>
            <article-id pub-id-type="publisher-id">PBIOLOGY-D-18-00631</article-id>
     
            <title-group>
                <article-title>Exact replication: Foundation of science or game of
                    chance?</article-title>
                <alt-title alt-title-type="running-head">The challenges of exact
                    replication</alt-title>
            </title-group>
            
            <contrib-group>
                <contrib>
                    <contrib-id authenticated="true" contrib-id-type="ORID"
                        >http://orcid.org/0000-0002-0147-8992</contrib-id>
                    <name>
                        <surname>Piper</surname>
                        <given-names>Sophie K.</given-names>
                    </name>
                    <xref rid="coi001"/>
                </contrib>
                <contrib>
                    <contrib-id authenticated="true" contrib-id-type="orcid"
                        >http://orcid.org/0000-0003-2595-0224</contrib-id>
                    <name>
                        <surname>Grittner</surname>
                        <given-names>Ulrike</given-names>
                    </name>
                </contrib>
                <aff>Affiliationo 1</aff>
                <aff><sup>2</sup>Affiliation 2<institution-wrap><institution-id institution-id-type="something">12</institution-id></institution-wrap><country country="US">USA</country></aff>
            </contrib-group>
         
        
             <author-notes>
                <fn fn-type="COI-statement" id="coi001">
                    <p>The authors have declared that no competing interests exist.</p>
                </fn>
                <corresp id="cor001">* E-mail: <email>ulrich.dirnagl@charite.de</email></corresp>
            </author-notes>
            <pub-date pub-type="epub">
                <day>9</day>
                <month>4</month>
                <year>2019</year>
            </pub-date>
            <pub-date pub-type="collection">
                <month>4</month>
                <year>2019</year>
            </pub-date>
            <pub-date pub-type="pmc-release">
                <day>9</day>
                <month>4</month>
                <year>2019</year>
            </pub-date>
            <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
            <volume>17</volume>
            <issue>4</issue>
            <elocation-id>e3000188</elocation-id>
            <permissions>
                <copyright-statement>&#x000a9; 2019 Piper et al</copyright-statement>
                <copyright-year>2019</copyright-year>
                <copyright-holder>Piper et al</copyright-holder>
                <license>
                    <ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                    <license-p>This is an open access article distributed under the terms of the
                            <ext-link ext-link-type="uri"
                            xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative
                            Commons Attribution License</ext-link>, which permits unrestricted use,
                        distribution, and reproduction in any medium, provided the original author
                        and source are credited.</license-p>
                </license>
            </permissions>
            <self-uri content-type="pdf" xlink:href="pbio.3000188.pdf"/>
            <abstract>
                <p>The need for replication of initial results has been rediscovered only recently
                    in many fields of research. In preclinical biomedical research, it is common
                    practice to conduct exact replications with the same sample sizes as those used
                    in the initial experiments. Such replication attempts, however, have lower
                    probability of replication than is generally appreciated. Indeed, in the common
                    scenario of an effect just reaching statistical significance, the statistical
                    power of the replication experiment assuming the same effect size is
                    approximately 50%&#x02014;in essence, a coin toss. Accordingly, we use the
                    provocative analogy of &#x0201c;replicating&#x0201d; a neuroprotective drug
                    animal study with a coin flip to highlight the need for larger sample sizes in
                    replication experiments. Additionally, we provide detailed background for the
                    probability of obtaining a significant <italic>p</italic> value in a replication
                    experiment and discuss the variability of <italic>p</italic> values as well as
                    pitfalls of simple binary significance testing in both initial preclinical
                    experiments and replication studies with small sample sizes. We conclude that
                    power analysis for determining the sample size for a replication study is
                    obligatory within the currently dominant hypothesis testing framework. Moreover,
                    publications should include effect size point estimates and corresponding
                    measures of precision, e.g., confidence intervals, to allow readers to assess
                    the magnitude and direction of reported effects and to potentially combine the
                    results of initial and replication study later through Bayesian or meta-analytic
                    approaches.</p>
            </abstract>
            <abstract abstract-type="toc">
                <p>Using a coin toss to &#x02018;replicate&#x02019; a neuroprotective effect of
                    valproic acid, this study highlights the fact that exact replications of
                    biomedical experiments are usually underpowered, often with power of
                    approximately 50%.</p>
            </abstract>
            <funding-group>
                <funding-statement>The authors received no specific funding for this
                    work.</funding-statement>
            </funding-group>
            <counts>
                <fig-count count="2"/>
                <table-count count="1"/>
                <page-count count="9"/>
            </counts>
            <custom-meta-group>
                <custom-meta id="data-availability">
                    <meta-name>Data Availability</meta-name>
                    <meta-value>All relevant data are within the paper and its Supporting
                        Information files.</meta-value>
                </custom-meta>
            </custom-meta-group>
        </article-meta>
        <notes>
            <title>Data Availability</title>
            <p>All relevant data are within the paper and its Supporting Information files.</p>
        </notes>
    </front>
    <body>
        <sec sec-type="intro" id="sec001">
            <title>Introduction</title>
            <disp-quote>
                <p>&#x0201c;Non-reproducible single occurrences are of no significance to
                    science.&#x0201d; [<xref rid="pbio.3000188.ref001" ref-type="bibr"
                    >1</xref>].</p>
            </disp-quote>



            <p>In modern times, replication 
                
                of results has been considered an integral part of the
                scientific process, at least, since Karl Popper&#x02019;s famous declaration [<xref
                    rid="pbio.3000188.ref002" ref-type="bibr">2</xref>], and has again taken center
                stage in discussions about current research and publication practices. Among the
                life sciences, psychology was the first field to attempt large scale replications of
                key research findings [<xref rid="pbio.3000188.ref005" ref-type="bibr">5</xref>],
                with discouraging results. Successful replications in these three multiexperiment
                metastudies varied from 39% to 67%, depending on the study and how replication was
                defined. An initially similarly large scale (but now much reduced) replication study
                in cancer biology [<xref rid="pbio.3000188.ref006" ref-type="bibr">6</xref>] has
                produced mixed results and has encountered difficulties in conducting replications,
                in part due to lack of methodological details in the original papers and the
                unavailability of reagents from the original labs. Anecdotal evidence from the
                pharmaceutical industry, however, suggests that exact replication success in the
                related field of drug development is low, found to be 11% by Begley and Ellis [<xref
                    rid="pbio.3000188.ref007" ref-type="bibr">7</xref>] and 26% by Prinz and
                colleagues [<xref rid="pbio.3000188.ref008" ref-type="bibr">8</xref>].</p>
            <p>As a consequence, many biomedical researchers are aware of potentially low
                replication rates across laboratories [<xref rid="pbio.3000188.ref009"
                    ref-type="bibr">9</xref>]. Largely unappreciated, however, are the potentially
                low replication rates of exact replications (also called &#x0201c;strict
                replications&#x0201d;) within laboratories, in which experiments are repeated with
                new samples with the same protocols and sample sizes. Unbeknownst to most
                researchers, however, using sample sizes identical to those of the initial
                experiments usually results in statistically underpowered replication attempts. At
                the extreme, the probability of obtaining a significant result in an exact
                replication of an initially barely significant result can be close to that of a coin
                toss [<xref rid="pbio.3000188.ref010" ref-type="bibr">10</xref>].</p>
            <p>We use an empirical example from our own research to highlight the generally low
                statistical power of same sample-size exact replications, with emphasis on the
                common scenario of a barely significant initial finding. Unconventionally to this
                end, we conduct a coin flip experiment in an attempt to &#x0201c;replicate&#x0201d;
                an animal experiment that found a small neuroprotective effect of valproic acid
                (VPA). We use this admittedly absurd procedure to provide the background for a
                broader discussion of the caveats and challenges implicated in replications of
                preclinical experiments. In particular, we discuss the variability of
                    <italic>p</italic> values in replication attempts as well as the pitfalls of
                simple binary (significant or not significant) testing.</p>
        </sec>
        <sec id="sec002">
            <title>The initial experiment</title>
            <p>VPA has been widely used as an anticonvulsant and mood-stabilizing drug for the
                treatment of epilepsy and bipolar disorders. Additional uses of the drug have been
                suggested by studies that have demonstrated its neuroprotective properties in rats
                    [<xref rid="pbio.3000188.ref011" ref-type="bibr">11</xref>, <xref
                    rid="pbio.3000188.ref012" ref-type="bibr">12</xref>]. Results from our group
                suggested such a protective effect of VPA in reducing brain infarct volumes in
                mice.</p>
            <p>In the experiment, 20 male C57Bl/6 N mice underwent transient intraluminal middle
                cerebral artery occlusion (MCAO) for 45 minutes (for detailed description, see <xref
                    ref-type="supplementary-material" rid="pbio.3000188.s003">S1 Text</xref>). Ten
                mice administered VPA (30 mg/kg, i.p., Desitin, Hamburg, Germany) were compared to
                10 animals administered vehicle only. Delivery was done immediately after
                reperfusion, 12 hours later, and then twice daily (every 12 hours) for 7 days. The
                primary outcome of interest was brain infarct measured in mm<sup>3</sup>. The VPA
                treated group displayed significantly lower infarct volumes (&#x02212;37%) compared
                with the vehicle treated group (mean: 39.4 mm<sup>3</sup>, standard deviation [SD]:
                27.6 mm<sup>3</sup> versus 63.6 mm<sup>3</sup>, SD: 22.7; <italic>n</italic> = 10
                per group; mean difference: 24.2 mm<sup>3</sup> with 95% confidence interval [CI;
                0.3&#x02013;48.0 mm<sup>3</sup>]; standardized effect size of 0.96 (95% CI:
                0.01&#x02013;1.87); t = 2.136; <italic>p</italic> = 0.047; see <xref
                    ref-type="supplementary-material" rid="pbio.3000188.s001">S1 Fig</xref>).</p>
   
        </sec>
        <sec id="sec004">
            <title>Replacing mice with dice?</title>
            <p>Given that the <italic>p</italic> value from the initial experiment was only slightly
                less than 0.05, we had initially planned to replicate our finding with a new mouse
                experiment. Assuming that the observed group means and their pooled SD equal the
                true population values, a formal power calculation for an exact replication (t-test
                for independent groups with a 0.05 two-sided alpha level and the same sample size of
                    <italic>n</italic> = 10 per group) yields a power of 52% (nQuery Advisor 7.0,
                Statistical Solutions Ltd, Cork, Ireland), i.e., approximately that of a coin
                flip.</p>
            <p>Rather than conduct a same sample-size exact replication as is typically done in
                biomedicine, however, we decided to attempt to &#x0201c;replicate&#x0201d; our
                initial findings by a probabilistically equivalent Bernoulli experiment&#x02014;a
                simple coin flip (see <xref ref-type="boxed-text" rid="pbio.3000188.box001">Box
                    1</xref> for a more detailed rationale). It should be noted that, as is true for
                any power estimation, our assumption that the observed effect in the initial
                experiment equals the population effect cannot be tested (i.e., the true population
                effect may be smaller or larger). Notwithstanding, this assumption is routinely used
                for power calculations in applied contexts because it is typically the best estimate
                available in preclinical research.</p>
            <boxed-text id="pbio.3000188.box001" position="float" orientation="portrait">
                <sec id="sec005">
                    <title>Box 1. Probability of successful replication</title>
                    <p>For a repetition of the experiment with the same sample size, intervention,
                        and groups, the probability of again obtaining a significant result is equal
                        to the power of the replication experiment with respect to identifying the
                        observed effect size from the first experiment [<xref
                            rid="pbio.3000188.ref010" ref-type="bibr">10</xref>]. In the case of a
                        t-test, the distribution of future results will follow a noncentral Student
                        t-distribution with N<sub>total</sub>-2 degrees of freedom and a
                        noncentrality parameter (ncp) that depends on the observed effect d of the
                        original study and the size n of each group: ncp = d*&#x0221a;(n/2). For a
                        single duplicate experiment, the probability of a statistically significant
                        result in in the same direction as the original experiment corresponds to
                        the area &#x003a6;t under the curve of the density function of the t
                        distribution beyond the critical value t&#x003b1;/2 for the corresponding
                        alpha error probability. In our original study, we had an effect size d of
                        0.957 with <italic>n</italic> = 10 per group corresponding to a ncp of 2.140
                        and a critical value t&#x003b1;/2 (for &#x003b1; = 0.05) of 2.101, resulting
                        in a probability of successful replication at the same alpha level of
                        &#x003a6;t (2.101, 2.140, df = 18) = 0.526. Because it is specified as a
                        replication experiment, this result does not depend on the power of the
                        original study [<xref rid="pbio.3000188.ref010" ref-type="bibr"
                        >10</xref>].</p>
                    <p>A caveat is needed regarding the coin flip analogy used in our study. The
                        analogy only holds under the assumption that the estimated effect size in
                        the first experiment equals the true population effect. In general, however,
                        data from initial experiments are consistent with a broad range of effect
                        sizes, as can be inferred from the wide confidence intervals associated with
                        the effects. <xref ref-type="fig" rid="pbio.3000188.g001">Fig 1</xref> shows
                        the power of a replication experiments with three different sample sizes as
                        a function of expected effect. Note that in our example, which has an
                        initial <italic>p</italic> less than but close to 0.05), tossing a coin has
                        approximately the same power as an exact replication to detect an effect
                        size as large as in experiment 1. The true population effect is unknown,
                        however, and may actually be null. In this latter scenario, replication
                        comes with the same 5% risk of an alpha error as in the initial
                        experiment.</p>
                </sec>
            </boxed-text>
            <fig id="pbio.3000188.g001" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pbio.3000188.g001</object-id>
                <label>Fig 1</label>
                <caption>
                    <title>Power of replication experiment depending on the expected effect size and
                        sample size.</title>
                    <p>Colored numerical values refer to our original experiment. Data of this
                        figure can be found in <xref ref-type="supplementary-material"
                            rid="pbio.3000188.s002">S1 Data</xref>, and the figure can be explored
                        further under s-quest.bihealth.org/power_replication/.</p>
                </caption>
                <graphic xlink:href="pbio.3000188.g001"/>
            </fig>
        </sec>
        <sec id="sec006">
            <title>An unconventional &#x0201c;replication&#x0201d; experiment</title>
            <p>For our unconventional replication experiment, we used a fair coin and a single coin
                flip to attempt to replicate the effectiveness of VPA on lowering brain infarct
                volumes. Study plan and procedure of the replication experiment were preregistered
                    [<xref rid="pbio.3000188.ref013" ref-type="bibr">13</xref>], and further details
                are given in <xref ref-type="supplementary-material" rid="pbio.3000188.s003">S1
                    Text</xref>. It was set a priori that if both observers judged the coin flip to
                have landed heads, the drug was deemed effective. The coin toss experiment took
                place on July 26, 2017, and was documented on video (<ext-link ext-link-type="uri"
                    xlink:href="https://www.youtube.com/watch?v=hhSbWARIEnM"
                    >https://www.youtube.com/watch?v=hhSbWARIEnM</ext-link>). Both observers agreed
                that the coin flip resulted in heads (<xref ref-type="fig" rid="pbio.3000188.g002"
                    >Fig 2</xref>), indicating the replication of the protective VPA effect on brain
                infarct volume found in the initial study.</p>
            <fig id="pbio.3000188.g002" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pbio.3000188.g002</object-id>
                <label>Fig 2</label>
                <caption>
                    <title>Results of the &#x0201c;replication&#x0201d; experiment.</title>
                    <p>Screenshots of the coin flip experiment: (A) blind selection of coin and (B)
                        flipping the coin (C) resulting in heads.</p>
                </caption>
                <graphic xlink:href="pbio.3000188.g002"/>
            </fig>
            <p>Clearly, we do not believe that a coin flip can help us to infer whether or not VPA
                has a beneficial neuroprotective effect. We use this absurd example to highlight the
                similarly absurd (from a frequentist probability perspective) exact replication
                scenario. In contrast to a coin toss, an exact replication would have consumed
                considerable resources with the suffering and death of 20 additional mice, but with
                no greater probability of replication than of our coin toss experiment (under the
                assumption that the initially observed effect equaled the population effect). Even
                if the initially observed <italic>p</italic> value had been substantially smaller
                than 0.05 (i.e., the estimate of the population effect had been considerably
                larger), the probability of successful replication at <italic>p</italic> &#x0003c;
                0.05 would still have been low when using the same sample size. For example, the
                probability of replication with an initial <italic>p</italic> value of 0.01 would
                only have been 73% in this scenario. To achieve 95% probability of replicating a
                significant <italic>p</italic> value with an exact replication, the initial
                    <italic>p</italic> value would have had to be <italic>p</italic> = 0.00032
                    [<xref rid="pbio.3000188.ref010" ref-type="bibr">10</xref>]. These facts are
                well known to statisticians. Indeed, a coin flip example is often used in teaching
                the positive predictive value of a statistically significant result [<xref
                    rid="pbio.3000188.ref014" ref-type="bibr">14</xref>]. Notwithstanding, most
                scientists who are conducting, contemplating, or interpreting replication
                experiments are unaware of them and of their consequences. As absurd as our
                &#x0201c;replication&#x0201d; experiment appears, it has a serious kernel. We chose
                this approach because we hope to provoke readers to consider the idiosyncrasies of
                replication study designs and to perhaps spark discussion amongst colleagues. We
                discuss additional issues pertinent to replications in the current biomedical
                research context.</p>
        </sec>
        <sec id="sec007">
            <title>Limitation of the binary approach of statistical testing in initial and
                replication experiments</title>
            <p>A <italic>p</italic> value alone has limited value and provides little information
                about the underlying effect of interest [<xref rid="pbio.3000188.ref014"
                    ref-type="bibr">14</xref>&#x02013;<xref rid="pbio.3000188.ref017"
                    ref-type="bibr">17</xref>]. This is true for any type of experiment, replication
                or otherwise.</p>
            <p>Because treatment effects measured in small samples have larger variability around
                their corresponding population effects (relative to treatment effects estimated with
                larger sample sizes), their associated <italic>p</italic> values will likewise be
                less reliable. Geoff Cumming used simulations and animated graphics to illustrate
                the large stochastic variability of <italic>p</italic> values, simply because of
                sampling variability [<xref rid="pbio.3000188.ref018" ref-type="bibr">18</xref>,
                    <xref rid="pbio.3000188.ref019" ref-type="bibr">19</xref>]. If power of the
                initial study is low, then the <italic>p</italic> value of the second study with the
                same sample size is likely to vary substantially from that observed in the first
                study [<xref rid="pbio.3000188.ref015" ref-type="bibr">15</xref>, <xref
                    rid="pbio.3000188.ref018" ref-type="bibr">18</xref>]. Moreover, Miller and
                Schwarz showed that the statistical uncertainty of the initial observed effect often
                prevents accurate estimation of the replication probability and concluded that it is
                essentially impossible to predict whether a single statistically significant finding
                will replicate [<xref rid="pbio.3000188.ref020" ref-type="bibr">20</xref>].
                According to this view, replications should not only be evaluated by whether they
                are statistically significant or not&#x02014;replications should not necessarily be
                characterized as successes or failures. Divergent statistical results in initial and
                replication experiments may occur, e.g., if statistical power is low in either one:
                a false positive might be observed by chance in the initial experiment, or a false
                negative in the replication [<xref rid="pbio.3000188.ref021" ref-type="bibr"
                    >21</xref>]. There are various metrics for concluding that replications have or
                have not been successful and how to use them to interpret divergent results [<xref
                    rid="pbio.3000188.ref022" ref-type="bibr">22</xref>, <xref
                    rid="pbio.3000188.ref023" ref-type="bibr">23</xref>].</p>
        </sec>
        <sec id="sec008">
            <title>Need for an effect size estimate in both initial and replication
                experiments</title>
            <p>Researchers are well advised to focus their research around the central question:
                &#x0201c;What is the effect (size)?&#x0201d; instead of the binary &#x0201c;Is there
                a statistically significant effect?&#x0201d; A <italic>p</italic> value is not
                solely a measure of an observed effect but depends on sample size as well;
                therefore, more information can be conveyed by reporting effect sizes [<xref
                    rid="pbio.3000188.ref018" ref-type="bibr">18</xref>]. Examining point estimates
                of effect sizes and measures of precision for both an initial experiment and its
                replication allows comparisons of the direction and of the strength of the observed
                effect in both studies. Effect size point estimates are less dependent on sample
                size and should be similar in both experiments if the replication was successful.
                Providing that the two experiments estimate the same underlying effect, providing
                point and precision estimates have the added advantage of allowing for Bayesian
                    [<xref rid="pbio.3000188.ref024" ref-type="bibr">24</xref>] or meta-analytic
                approaches [<xref rid="pbio.3000188.ref025" ref-type="bibr">25</xref>], which
                combine evidence of the original (prior) with the new data (replication experiment)
                to gain more reliable evidence.</p>
        </sec>
        <sec id="sec009">
            <title>Power considerations are pivotal for replication studies</title>
            <p>Power considerations should be obligatory for both initial experiments and for their
                replications [<xref rid="pbio.3000188.ref015" ref-type="bibr">15</xref>, <xref
                    rid="pbio.3000188.ref026" ref-type="bibr">26</xref>, <xref
                    rid="pbio.3000188.ref027" ref-type="bibr">27</xref>]. In order to reject the
                null hypothesis efficiently in a replication experiment, a (typically substantial)
                increase in sample size is necessary [<xref rid="pbio.3000188.ref028"
                    ref-type="bibr">28</xref>].</p>
            <p>Simonsohn [<xref rid="pbio.3000188.ref029" ref-type="bibr">29</xref>] looked at the
                replication problem the other way around and proposed to use 2.5&#x000d7; the sample
                size of the original experiment to obtain 80% power to reject the hypothesis of a
                detectable effect, e.g., an effect that the original sample had 33% power to detect,
                assuming the true effect is zero (note that the null hypothesis here is that there
                is an effect, and the alternative hypothesis is that there is no effect at all).
                Lakens as well as Neumann and colleagues suggested to use group sequential designs
                with stopping rules for success and futility, and calculation of <italic>p</italic>
                value and Bayes factor in parallel [<xref rid="pbio.3000188.ref030" ref-type="bibr"
                    >30</xref>, <xref rid="pbio.3000188.ref031" ref-type="bibr">31</xref>]. Although
                sequential analyses aim to test hypotheses rather than to provide accurate effect
                size estimates, the latter can only be reached by larger sample sizes or
                meta-analyses [<xref rid="pbio.3000188.ref032" ref-type="bibr">32</xref>].</p>
            <p>To further explore and understand the role of power in replication experiments, we
                provide a web application in which initial sample size, initial results, and sample
                size of the replication experiment can be manipulated for determining power of a
                replication experiment under different scenarios
                (s-quest.bihealth.org/power_replication/). <xref ref-type="fig"
                    rid="pbio.3000188.g001">Fig 1</xref> shows the power of the replication
                experiment depending on sample size and expected effect with our web
                application.</p>
            <p>Three observations are noteworthy: (1) Assuming that the effect observed in our
                original experiment equals the population effect, an exact replication with the same
                sample size yields 52.5% power of detecting an effect with alpha set to 0.05, which
                motivated our coin flip analogy. (2) Under this same scenario, considerably larger
                sample sizes per group would have been necessary for a high-powered replication
                experiment (<italic>n</italic> = 25 for power = 91.1% and <italic>n</italic> = 50
                for 99.7% power). (3) Under the assumption that the true population effect is zero,
                there is a 5% probability that the null hypothesis would nonetheless have been
                falsely rejected under all sample size scenarios, replicating the original
                experiment&#x02019;s false positive finding (Type I error).</p>
        </sec>
        <sec id="sec010">
            <title>Increased generalizability through conceptual rather than exact
                replication</title>
            <p>Exact replications, regardless of using the same or an increased sample size compared
                with the initial experiment, can only show whether a certain effect can be
                replicated in a specific setting. However, to what extent the same effect can also
                be generalized can only be learned from replications that vary some aspect of the
                original design (e.g., different species, different laboratory, etc.) and thus
                increase the external validity of the results [<xref rid="pbio.3000188.ref002"
                    ref-type="bibr">2</xref>]. Such conceptual replications are particularly
                important when translating preclinical findings in animals to humans, because
                clinical trial in humans cannot exactly replicate animal studies.</p>
            <p>In <xref rid="pbio.3000188.t001" ref-type="table">Table 1</xref>, we provide an
                overview of what additional information could be gained by performing an exact
                replication with or without an increase in power, as well as from conceptual
                replication, all compared to a coin toss. As argued above, an exact replication with
                the same sample size is potentially useful for identifying technical problems in the
                initial experiment, and the data can be used in meta-analytical or Bayesian
                approaches for more precise point estimates. By contrast, conceptual replication
                probes the robustness of results. If dissimilarities are observed between the
                initial experiment and the conceptual replication, however, it is unknown whether
                this is caused by false inference in the initial experiment (i.e., there is no true
                effect) or whether the two experiments are in fact addressing two different research
                questions, showing that there is value in performing both types of replications.</p>
            <table-wrap id="pbio.3000188.t001" orientation="portrait" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pbio.3000188.t001</object-id>
                <label>Table 1</label>
                <caption>
                    <title>Attributes and applications of different methods of replication.</title>
                </caption>
                <alternatives>
                    <graphic id="pbio.3000188.t001g" xlink:href="pbio.3000188.t001"/>
                    <table frame="hsides" rules="groups">
                        <colgroup span="1">
                            <col align="left" valign="middle" span="1"/>
                            <col align="left" valign="middle" span="1"/>
                            <col align="left" valign="middle" span="1"/>
                            <col align="left" valign="middle" span="1"/>
                            <col align="left" valign="middle" span="1"/>
                        </colgroup>
                        <thead>
                            <tr>
                                <th align="left"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Method of
                                    replication/<break/>Attributes</th>
                                <th align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Coin flip replication</th>
                                <th align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Exact replication (same design, same
                                    sample size)</th>
                                <th align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Exact replication with increased sample
                                    size (e.g., 2.5&#x000d7; sample size of initial study)</th>
                                <th align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted"
                                    rowspan="1" colspan="1">Conceptual replication (meaningful
                                    alterations to design, varying sample size)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td align="left"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Can identify technical mistakes in
                                    initial experiment</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">yes</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">yes</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted"
                                    rowspan="1" colspan="1">maybe</td>
                            </tr>
                            <tr>
                                <td align="left"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Can be used to reduce false inference on
                                    treatment effects</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">maybe</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">yes</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted"
                                    rowspan="1" colspan="1">maybe</td>
                            </tr>
                            <tr>
                                <td align="left"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Can provide information on
                                    robustness</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted"
                                    rowspan="1" colspan="1">yes</td>
                            </tr>
                            <tr>
                                <td align="left"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">Can be used for meta-analyses</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">no</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">yes</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted;border-right:dotted"
                                    rowspan="1" colspan="1">yes</td>
                                <td align="center"
                                    style="border-top:dotted;border-bottom:dotted;border-left:dotted"
                                    rowspan="1" colspan="1">maybe</td>
                            </tr>
                        </tbody>
                    </table>
                </alternatives>
            </table-wrap>
            <p>We used the apparently fallacious example of combining an animal experiment with a
                game of chance to illustrate and discuss the statistical challenges and complexities
                of replication experiments. We stress, however, that our argument here is not that
                exact replication does not have a role in the scientific process. In fact, it has a
                very useful but also limited and specific purpose. Although reproducibility is a
                complex construct [<xref rid="pbio.3000188.ref021" ref-type="bibr">21</xref>, <xref
                    rid="pbio.3000188.ref033" ref-type="bibr">33</xref>, <xref
                    rid="pbio.3000188.ref034" ref-type="bibr">34</xref>], there appears to be
                consensus that replicability of results within one laboratory (&#x0201c;exact
                replication&#x0201d;) is an important element of the scientific method. All efforts
                should be made to make research replicable; i.e., the methodology should be thus
                designed and described that others (hypothetically) could repeat the experiment. An
                exact replication can increase the confidence in an experimental finding and rule
                out experimental, statistical, and other artifacts [<xref rid="pbio.3000188.ref002"
                    ref-type="bibr">2</xref>]. However, scientists, who with the best of intentions
                replicate their pivotal results with the same sample size, should be aware of the
                limitations of this procedure. Confidence in the results can be achieved in the
                first instance by exact replication (when possible) but with increased sample size
                to provide adequate power. Confidence in the robustness and generizability of
                results can be best achieved with adequately powered conceptual replications across
                multiple laboratories [<xref rid="pbio.3000188.ref035" ref-type="bibr"
                >35</xref>].</p>
        </sec>
        <sec sec-type="conclusions" id="sec011">
            <title>Conclusions</title>
            <p>We describe the design and results of a preregistered animal experiment to establish
                the efficacy of VPA to reduce brain infarct volumes in murine stroke, which we
                combine with a coin toss as a substitute for an exact replication. The absurd but
                true notion that a coin flip provides approximately the same positive predictive
                value as an exact replication experiment when the initial effect is barely
                significant highlights an important, but little known, limitation of exact
                replications. Although replication is a complex construct that eludes simple
                definition, we can learn from both successful and failed replication attempts [<xref
                    rid="pbio.3000188.ref036" ref-type="bibr">36</xref>], provided that we avoid
                underpowered initial and replication experiments. Moreover, effect sizes and
                corresponding measures of precision should be prioritized over reference to
                statistical significance.</p>
        </sec>
        <sec sec-type="supplementary-material" id="sec012">
            <title>Supporting information</title>
            <supplementary-material content-type="local-data" id="pbio.3000188.s001">
                <label>S1 Fig</label>
                <caption>
                    <title>Results of the original experiment.</title>
                    <p>Brain infarct volumes with and without treatment of VPA. <italic>N</italic> =
                        10 per group. Box plots represent median, 25th and 75th percentile, mean
                        (dotted line), 5th and 95th percentile (whiskers) and, additionally, the
                        individual data points that are also given in <xref
                            ref-type="supplementary-material" rid="pbio.3000188.s002">S1
                        Data</xref>.</p>
                    <p>(TIF)</p>
                </caption>
                <media xlink:href="pbio.3000188.s001.tif">
                    <caption>
                        <p>Click here for additional data file.</p>
                    </caption>
                </media>
            </supplementary-material>
            <supplementary-material content-type="local-data" id="pbio.3000188.s002">
                <label>S1 Data</label>
                <caption>
                    <title>Data for <xref ref-type="fig" rid="pbio.3000188.g001">Fig 1</xref> and
                            <xref ref-type="supplementary-material" rid="pbio.3000188.s001">S1
                            Fig</xref>.</title>
                    <p>(XLSX)</p>
                </caption>
                <media xlink:href="pbio.3000188.s002.xlsx">
                    <caption>
                        <p>Click here for additional data file.</p>
                    </caption>
                </media>
            </supplementary-material>
            <supplementary-material content-type="local-data" id="pbio.3000188.s003">
                <label>S1 Text</label>
                <caption>
                    <title>Methods original and &#x02018;replication&#x02019; experiment.</title>
                    <p>(DOCX)</p>
                </caption>
                <media xlink:href="pbio.3000188.s003.docx">
                    <caption>
                        <p>Click here for additional data file.</p>
                    </caption>
                </media>
            </supplementary-material>
        </sec>
    </body>
    <back>
        <sec id="sec003" sec-type="data-availability">
            <title>Data Availability</title>
            <p>All animal experiments, inclusive of the welfare-related assessments and
                interventions that were carried out prior to, during, or after the experiment,
                were performed according to protocols approved by the Berlin Authorities (ethics
                committee of the &#x0201c;Landesamt f&#x000fc;r Gesundheit und Soziales
                Berlin,&#x0201d; LaGeSo Reg 390/09).</p>
        </sec>
             <fn-group>
            <fn fn-type="other" id="fn001">
                <p><bold>Provenance:</bold> Not commissioned; externally peer reviewed.</p>
            </fn>
        </fn-group>
        <ack>
            <p>We thank John Ioannidis (METRICS, Stanford University, USA) for critical and
                stimulating discussions.</p>
        </ack>
        <glossary>
            <title>Abbreviations</title>
            <def-list>
                <def-item>
                    <term>CI</term>
                    <def>
                        <p>confidence interval</p>
                    </def>
                </def-item>
                <def-item>
                    <term>MCAO</term>
                    <def>
                        <p>middle cerebral artery occlusion</p>
                    </def>
                </def-item>
                <def-item>
                    <term>ncp</term>
                    <def>
                        <p>noncentrality parameter</p>
                    </def>
                </def-item>
                <def-item>
                    <term>SD</term>
                    <def>
                        <p>standard deviation</p>
                    </def>
                </def-item>
                <def-item>
                    <term>VPA</term>
                    <def>
                        <p>valproic acid</p>
                    </def>
                </def-item>
            </def-list>
        </glossary>
        <ref-list>
            <title>References</title>
            <ref id="pbio.3000188.ref001">
                <label>1</label>
                <mixed-citation publication-type="book">
                    <name>
                        <surname>Popper</surname>
                        <given-names>KR</given-names>
                    </name>
                    <source>Logik der Forschung: zur Erkenntnistheorie der moderner
                        Naturwissenschaft</source>
                    <publisher-name>Verlag von Julius Springer</publisher-name>
                    <year>1935</year>
                </mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref002">
                <label>2</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Schmidt</surname>
                        <given-names>S</given-names>
                    </name>. <article-title>Shall we really do it again? The powerful concept of
                        replication is neglected in the social sciences</article-title>.
                        <source>Review of General Psychology</source>.
                        <year>2009</year>;<volume>13</volume>(<issue>2</issue>):<fpage>90</fpage>.</mixed-citation>
            </ref>
            <ref id="R2">
                <label>3</label>
                <mixed-citation publication-type="journal"><collab>Open Science C</collab>.
                        <article-title>PSYCHOLOGY. Estimating the reproducibility of psychological
                        science</article-title>. <source>Science</source>.
                        <year>2015</year>;<volume>349</volume>(<issue>6251</issue>):<fpage>aac4716</fpage>
                    Epub 2015/09/01. <pub-id pub-id-type="doi">10.1126/science.aac4716</pub-id>
                        .<?supplied-pmid 26315443?><pub-id pub-id-type="pmid"
                    >26315443</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref004">
                <label>4</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Klein</surname>
                        <given-names>RA</given-names>
                    </name>, <name>
                        <surname>Vianello</surname>
                        <given-names>M</given-names>
                    </name>, <name>
                        <surname>Hasselman</surname>
                        <given-names>F</given-names>
                    </name>, <name>
                        <surname>Adams</surname>
                        <given-names>BG</given-names>
                    </name>, <name>
                        <surname>Adams</surname>
                        <given-names>RB</given-names>
                    </name>, <name>
                        <surname>Alper</surname>
                        <given-names>S</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Many Labs 2: Investigating variation in replicability across
                        sample and setting</article-title>. <source>Advances in Methods and
                        Practices in Psychological Science</source>. <year>2018</year>
                    <pub-id pub-id-type="doi">10.1177/2515245918754485</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref005">
                <label>5</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Camerer</surname>
                        <given-names>CF</given-names>
                    </name>, <name>
                        <surname>Dreber</surname>
                        <given-names>A</given-names>
                    </name>, <name>
                        <surname>Holzmeister</surname>
                        <given-names>F</given-names>
                    </name>, <name>
                        <surname>Ho</surname>
                        <given-names>T-H</given-names>
                    </name>, <name>
                        <surname>Huber</surname>
                        <given-names>J</given-names>
                    </name>, <name>
                        <surname>Johannesson</surname>
                        <given-names>M</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Evaluating the replicability of social science experiments in
                        Nature and Science between 2010 and 2015</article-title>. <source>Nature
                        Human Behaviour</source>.
                    <year>2018</year>:<volume>1</volume>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref006">
                <label>6</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Kaiser</surname>
                        <given-names>J</given-names>
                    </name>. <article-title>Plan to replicate 50 high-impact cancer papers shrinks
                        to just 18</article-title>. <source>Science</source>.
                        <year>2018</year>;<volume>243</volume>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref007">
                <label>7</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Begley</surname>
                        <given-names>CG</given-names>
                    </name>, <name>
                        <surname>Ellis</surname>
                        <given-names>LM</given-names>
                    </name>. <article-title>Drug development: Raise standards for preclinical cancer
                        research</article-title>. <source>Nature</source>.
                        <year>2012</year>;<volume>483</volume>(<issue>7391</issue>):<fpage>531</fpage>
                    <pub-id pub-id-type="doi">10.1038/483531a</pub-id>
                    <?supplied-pmid 22460880?><pub-id pub-id-type="pmid"
                    >22460880</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref008">
                <label>8</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Prinz</surname>
                        <given-names>F</given-names>
                    </name>, <name>
                        <surname>Schlange</surname>
                        <given-names>T</given-names>
                    </name>, <name>
                        <surname>Asadullah</surname>
                        <given-names>K</given-names>
                    </name>. <article-title>Believe it or not: how much can we rely on published
                        data on potential drug targets?</article-title>
                    <source>Nature reviews Drug discovery</source>.
                        <year>2011</year>;<volume>10</volume>(<issue>9</issue>):<fpage>712</fpage>
                    <pub-id pub-id-type="doi">10.1038/nrd3439-c1</pub-id>
                    <?supplied-pmid 21892149?><pub-id pub-id-type="pmid"
                    >21892149</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref009">
                <label>9</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Baker</surname>
                        <given-names>M</given-names>
                    </name>. <article-title>1,500 scientists lift the lid on
                        reproducibility</article-title>. <source>Nature</source>.
                        <year>2016</year>;<volume>533</volume>(<issue>7604</issue>):<fpage>452</fpage>&#x02013;<lpage>4</lpage>.
                    Epub 2016/05/27. <pub-id pub-id-type="doi">10.1038/533452a</pub-id>
                        .<?supplied-pmid 27225100?><pub-id pub-id-type="pmid"
                    >27225100</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref010">
                <label>10</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Goodman</surname>
                        <given-names>SN</given-names>
                    </name>. <article-title>A comment on replication, p-values and
                        evidence</article-title>. <source>Stat Med</source>.
                        <year>1992</year>;<volume>11</volume>(<issue>7</issue>):<fpage>875</fpage>&#x02013;<lpage>9</lpage>.
                    Epub 1992/05/01. .<?supplied-pmid 1604067?><pub-id pub-id-type="pmid"
                        >1604067</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref011">
                <label>11</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Suda</surname>
                        <given-names>S</given-names>
                    </name>, <name>
                        <surname>Ueda</surname>
                        <given-names>M</given-names>
                    </name>, <name>
                        <surname>Nito</surname>
                        <given-names>C</given-names>
                    </name>, <name>
                        <surname>Nishiyama</surname>
                        <given-names>Y</given-names>
                    </name>, <name>
                        <surname>Okubo</surname>
                        <given-names>S</given-names>
                    </name>, <name>
                        <surname>Abe</surname>
                        <given-names>A</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Valproic acid ameliorates ischemic brain injury in hyperglycemic
                        rats with permanent middle cerebral occlusion</article-title>. <source>Brain
                        research</source>.
                        <year>2015</year>;<volume>1606</volume>:<fpage>1</fpage>&#x02013;<lpage>8</lpage>.
                        <pub-id pub-id-type="doi">10.1016/j.brainres.2015.02.013</pub-id>
                    <?supplied-pmid 25721785?><pub-id pub-id-type="pmid"
                    >25721785</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref012">
                <label>12</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Wang</surname>
                        <given-names>Z</given-names>
                    </name>, <name>
                        <surname>Tsai</surname>
                        <given-names>L-K</given-names>
                    </name>, <name>
                        <surname>Munasinghe</surname>
                        <given-names>J</given-names>
                    </name>, <name>
                        <surname>Leng</surname>
                        <given-names>Y</given-names>
                    </name>, <name>
                        <surname>Fessler</surname>
                        <given-names>EB</given-names>
                    </name>, <name>
                        <surname>Chibane</surname>
                        <given-names>F</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Chronic valproate treatment enhances postischemic angiogenesis
                        and promotes functional recovery in a rat model of ischemic
                        stroke</article-title>. <source>Stroke</source>.
                        <year>2012</year>;<volume>43</volume>(<issue>9</issue>):<fpage>2430</fpage>&#x02013;<lpage>6</lpage>.
                        <pub-id pub-id-type="doi">10.1161/STROKEAHA.112.652545</pub-id>
                    <?supplied-pmid 22811460?><pub-id pub-id-type="pmid"
                    >22811460</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref013">
                <label>13</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Dirnagl</surname>
                        <given-names>U</given-names>
                    </name>, <name>
                        <surname>Grittner</surname>
                        <given-names>U</given-names>
                    </name>, <name>
                        <surname>Ioannidis</surname>
                        <given-names>JPA</given-names>
                    </name>, <name>
                        <surname>Nadon</surname>
                        <given-names>R</given-names>
                    </name>, <name>
                        <surname>Piper</surname>
                        <given-names>SK</given-names>
                    </name>, <name>
                        <surname>Rex</surname>
                        <given-names>A</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Neuroprotective efficacy of valproate in stroke: Replacing
                        preclinical replication experiments by flipping coins?</article-title>
                    Retrieved from osf.io/gztjb. <year>2017</year>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref014">
                <label>14</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Nuzzo</surname>
                        <given-names>R</given-names>
                    </name>. <article-title>Scientific method: statistical errors</article-title>.
                        <source>Nature News</source>.
                        <year>2014</year>;<volume>506</volume>(<issue>7487</issue>):<fpage>150</fpage>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref015">
                <label>15</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Halsey</surname>
                        <given-names>LG</given-names>
                    </name>, <name>
                        <surname>Curran-Everett</surname>
                        <given-names>D</given-names>
                    </name>, <name>
                        <surname>Vowler</surname>
                        <given-names>SL</given-names>
                    </name>, <name>
                        <surname>Drummond</surname>
                        <given-names>GB</given-names>
                    </name>. <article-title>The fickle P value generates irreproducible
                        results</article-title>. <source>Nat Methods</source>.
                        <year>2015</year>;<volume>12</volume>(<issue>3</issue>):<fpage>179</fpage>&#x02013;<lpage>85</lpage>.
                    Epub 2015/02/27. <pub-id pub-id-type="doi">10.1038/nmeth.3288</pub-id>
                        .<?supplied-pmid 25719825?><pub-id pub-id-type="pmid"
                    >25719825</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref016">
                <label>16</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Senn</surname>
                        <given-names>S</given-names>
                    </name>, <name>
                        <surname>Goodman</surname>
                        <given-names>SN</given-names>
                    </name>. <article-title>A comment on replication, p-values and
                        evidence</article-title>. <source>Author's reply. Statistics in
                        medicine</source>.
                        <year>2002</year>;<volume>21</volume>(<issue>16</issue>):<fpage>2437</fpage>&#x02013;<lpage>47</lpage>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref017">
                <label>17</label>
                <mixed-citation publication-type="book"><name>
                        <surname>Wasserstein</surname>
                        <given-names>RL</given-names>
                    </name>, <name>
                        <surname>Lazar</surname>
                        <given-names>NA</given-names>
                    </name>. <source>T</source><chapter-title>he ASA's statement on p-values:
                        context, process, and purpose</chapter-title>
                    <publisher-name>Taylor &#x00026; Francis</publisher-name>;
                    <year>2016</year>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref018">
                <label>18</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Cumming</surname>
                        <given-names>G</given-names>
                    </name>. <article-title>Replication and p Intervals: p Values Predict the Future
                        Only Vaguely, but Confidence Intervals Do Much Better</article-title>.
                        <source>Perspect Psychol Sci</source>.
                        <year>2008</year>;<volume>3</volume>(<issue>4</issue>):<fpage>286</fpage>&#x02013;<lpage>300</lpage>.
                    Epub 2008/07/01. <pub-id pub-id-type="doi"
                        >10.1111/j.1745-6924.2008.00079.x</pub-id>
                        .<?supplied-pmid 26158948?><pub-id pub-id-type="pmid"
                    >26158948</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref019">
                <label>19</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Cumming</surname>
                        <given-names>G</given-names>
                    </name>. <source>Intro statistics 9: dance of the P values</source>
                    <year>2013</year> Available from: <ext-link ext-link-type="uri"
                        xlink:href="https://www.youtube.com/watch?v=5OL1RqHrZQ8"
                        >https://www.youtube.com/watch?v=5OL1RqHrZQ8</ext-link>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref020">
                <label>20</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Miller</surname>
                        <given-names>J</given-names>
                    </name>, <name>
                        <surname>Schwarz</surname>
                        <given-names>W</given-names>
                    </name>. <article-title>Aggregate and individual replication probability within
                        an explicit model of the research process</article-title>.
                        <source>Psychological methods</source>.
                        <year>2011</year>;<volume>16</volume>(<issue>3</issue>):<fpage>337</fpage>
                    <pub-id pub-id-type="doi">10.1037/a0023347</pub-id>
                    <?supplied-pmid 21534683?><pub-id pub-id-type="pmid"
                    >21534683</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref021">
                <label>21</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Dirnagl</surname>
                        <given-names>U</given-names>
                    </name>. <article-title>Rethinking research reproducibility</article-title>.
                        <source>The EMBO Journal</source>. <year>2018</year>:<fpage>e101117</fpage>
                    <pub-id pub-id-type="doi">10.15252/embj.2018101117</pub-id>
                    <?supplied-pmid 30518534?><pub-id pub-id-type="pmid"
                    >30518534</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref022">
                <label>22</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Nosek</surname>
                        <given-names>BA</given-names>
                    </name>, <name>
                        <surname>Errington</surname>
                        <given-names>TM</given-names>
                    </name>. <article-title>Reproducibility in cancer biology: making sense of
                        replications</article-title>. <source>Elife</source>.
                        <year>2017</year>;<volume>6</volume>:<fpage>e23383</fpage>
                    <pub-id pub-id-type="doi">10.7554/eLife.23383</pub-id>
                    <?supplied-pmid 28100398?><pub-id pub-id-type="pmid"
                    >28100398</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref023">
                <label>23</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Aarts</surname>
                        <given-names>AA</given-names>
                    </name>, <name>
                        <surname>Anderson</surname>
                        <given-names>JE</given-names>
                    </name>, <name>
                        <surname>Anderson</surname>
                        <given-names>CJ</given-names>
                    </name>, <name>
                        <surname>Attridge</surname>
                        <given-names>PR</given-names>
                    </name>, <name>
                        <surname>Attwood</surname>
                        <given-names>A</given-names>
                    </name>, <name>
                        <surname>Axt</surname>
                        <given-names>J</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Estimating the reproducibility of psychological
                        science</article-title>. <source>Science</source>.
                        <year>2015</year>;<volume>349</volume>(<issue>6251</issue>):<fpage>253</fpage>&#x02013;<lpage>67</lpage>.<pub-id
                        pub-id-type="pmid">26185242</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref024">
                <label>24</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Vasishth</surname>
                        <given-names>S</given-names>
                    </name>, <name>
                        <surname>Mertzen</surname>
                        <given-names>D</given-names>
                    </name>, <name>
                        <surname>J&#x000e4;ger</surname>
                        <given-names>LA</given-names>
                    </name>. <source>The statistical significance filter leads to overoptimistic
                        expectations of replicability</source>. <year>2018</year>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref025">
                <label>25</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Klein</surname>
                        <given-names>R</given-names>
                    </name>, <name>
                        <surname>Ratliff</surname>
                        <given-names>K</given-names>
                    </name>, <name>
                        <surname>Nosek</surname>
                        <given-names>B</given-names>
                    </name>, <name>
                        <surname>Vianello</surname>
                        <given-names>M</given-names>
                    </name>, <name>
                        <surname>Pilati</surname>
                        <given-names>R</given-names>
                    </name>, <name>
                        <surname>Devos</surname>
                        <given-names>T</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Investigating variation in replicability: The &#x0201c;many
                        labs&#x0201d; replication project</article-title>. <source>Retrieved from
                        Open Science Framework</source>. <year>2014</year>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref026">
                <label>26</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Goodman</surname>
                        <given-names>SN</given-names>
                    </name>, <name>
                        <surname>Berlin</surname>
                        <given-names>JA</given-names>
                    </name>. <article-title>The use of predicted confidence intervals when planning
                        experiments and the misuse of power when interpreting
                        results</article-title>. <source>Annals of internal medicine</source>.
                        <year>1994</year>;<volume>121</volume>(<issue>3</issue>):<fpage>200</fpage>&#x02013;<lpage>6</lpage>.
                        <?supplied-pmid 8017747?><pub-id pub-id-type="pmid"
                    >8017747</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref027">
                <label>27</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Albers</surname>
                        <given-names>C</given-names>
                    </name>, <name>
                        <surname>Lakens</surname>
                        <given-names>D</given-names>
                    </name>. <article-title>When power analyses based on pilot data are biased:
                        Inaccurate effect size estimators and follow-up bias</article-title>.
                        <source>Journal of Experimental Social Psychology</source>.
                        <year>2018</year>;<volume>74</volume>:<fpage>187</fpage>&#x02013;<lpage>95</lpage>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref028">
                <label>28</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Lakens</surname>
                        <given-names>D</given-names>
                    </name>. <article-title>How many participants should you
                        collect?</article-title>
                    <source>An alternative to the N * 2.5 rule</source>
                    <year>2015</year> [cited 2017]. Available from: <ext-link ext-link-type="uri"
                        xlink:href="http://daniellakens.blogspot.de/2015/04/how-many-participants-should-you.html"
                        >http://daniellakens.blogspot.de/2015/04/how-many-participants-should-you.html</ext-link></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref029">
                <label>29</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Simonsohn</surname>
                        <given-names>U</given-names>
                    </name>. <article-title>Small telescopes: detectability and the evaluation of
                        replication results</article-title>. <source>Psychol Sci</source>.
                        <year>2015</year>;<volume>26</volume>(<issue>5</issue>):<fpage>559</fpage>&#x02013;<lpage>69</lpage>.
                    Epub 2015/03/25. <pub-id pub-id-type="doi">10.1177/0956797614567341</pub-id>
                        .<?supplied-pmid 25800521?><pub-id pub-id-type="pmid"
                    >25800521</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref030">
                <label>30</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Neumann</surname>
                        <given-names>K</given-names>
                    </name>, <name>
                        <surname>Grittner</surname>
                        <given-names>U</given-names>
                    </name>, <name>
                        <surname>Piper</surname>
                        <given-names>SK</given-names>
                    </name>, <name>
                        <surname>Rex</surname>
                        <given-names>A</given-names>
                    </name>, <name>
                        <surname>Florez-Vargas</surname>
                        <given-names>O</given-names>
                    </name>, <name>
                        <surname>Karystianis</surname>
                        <given-names>G</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Increasing efficiency of preclinical research by group sequential
                        designs</article-title>. <source>PLoS Biol</source>.
                        <year>2017</year>;<volume>15</volume>(<issue>3</issue>):<fpage>e2001307</fpage>
                    <pub-id pub-id-type="doi">10.1371/journal.pbio.2001307</pub-id>
                    <?supplied-pmid 28282371?><pub-id pub-id-type="pmid"
                    >28282371</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref031">
                <label>31</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Lakens</surname>
                        <given-names>D</given-names>
                    </name>. <article-title>Performing high&#x02010;powered studies efficiently with
                        sequential analyses</article-title>. <source>European Journal of Social
                        Psychology</source>.
                        <year>2014</year>;<volume>44</volume>(<issue>7</issue>):<fpage>701</fpage>&#x02013;<lpage>10</lpage>.</mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref032">
                <label>32</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Lakens</surname>
                        <given-names>D</given-names>
                    </name>, <name>
                        <surname>Evers</surname>
                        <given-names>ER</given-names>
                    </name>. <article-title>Sailing from the seas of chaos into the corridor of
                        stability: Practical recommendations to increase the informational value of
                        studies</article-title>. <source>Perspectives on Psychological
                        Science</source>.
                        <year>2014</year>;<volume>9</volume>(<issue>3</issue>):<fpage>278</fpage>&#x02013;<lpage>92</lpage>.
                        <pub-id pub-id-type="doi">10.1177/1745691614528520</pub-id>
                    <?supplied-pmid 26173264?><pub-id pub-id-type="pmid"
                    >26173264</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref033">
                <label>33</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Goodman</surname>
                        <given-names>SN</given-names>
                    </name>, <name>
                        <surname>Fanelli</surname>
                        <given-names>D</given-names>
                    </name>, <name>
                        <surname>Ioannidis</surname>
                        <given-names>JP</given-names>
                    </name>. <article-title>What does research reproducibility mean?</article-title>
                    <source>Science translational medicine</source>.
                        <year>2016</year>;<volume>8</volume>(<issue>341</issue>):<fpage>341ps12</fpage>&#x02013;<lpage>ps12</lpage>.
                        <pub-id pub-id-type="doi">10.1126/scitranslmed.aaf5027</pub-id>
                    <?supplied-pmid 27252173?><pub-id pub-id-type="pmid"
                    >27252173</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref034">
                <label>34</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Blainey</surname>
                        <given-names>P</given-names>
                    </name>, <name>
                        <surname>Krzywinski</surname>
                        <given-names>M</given-names>
                    </name>, <name>
                        <surname>Altman</surname>
                        <given-names>N</given-names>
                    </name>. <article-title>Replication: quality is often more important than
                        quantity</article-title>. <source>Nature Methods</source>.
                        <year>2014</year>;<volume>11</volume>(<issue>9</issue>):<fpage>879</fpage>&#x02013;<lpage>81</lpage>.
                        <?supplied-pmid 25317452?><pub-id pub-id-type="pmid"
                    >25317452</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref035">
                <label>35</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Llovera</surname>
                        <given-names>G</given-names>
                    </name>, <name>
                        <surname>Hofmann</surname>
                        <given-names>K</given-names>
                    </name>, <name>
                        <surname>Roth</surname>
                        <given-names>S</given-names>
                    </name>, <name>
                        <surname>Salas-P&#x000e9;rdomo</surname>
                        <given-names>A</given-names>
                    </name>, <name>
                        <surname>Ferrer-Ferrer</surname>
                        <given-names>M</given-names>
                    </name>, <name>
                        <surname>Perego</surname>
                        <given-names>C</given-names>
                    </name>, <etal>et al</etal>
                    <article-title>Results of a preclinical randomized controlled multicenter trial
                        (pRCT): Anti-CD49d treatment for acute brain ischemia</article-title>.
                        <source>Science Translational Medicine</source>.
                        <year>2015</year>;<volume>7</volume>(<issue>299</issue>):<fpage>299ra121</fpage>&#x02013;<lpage>299ra121</lpage>.
                        <pub-id pub-id-type="doi">10.1126/scitranslmed.aaa9853</pub-id>
                    <?supplied-pmid 26246166?><pub-id pub-id-type="pmid"
                    >26246166</pub-id></mixed-citation>
            </ref>
            <ref id="pbio.3000188.ref036">
                <label>36</label>
                <mixed-citation publication-type="journal"><name>
                        <surname>Ioannidis</surname>
                        <given-names>JPA</given-names>
                    </name>. <article-title>The Reproducibility Wars: Successful, Unsuccessful,
                        Uninterpretable, Exact, Conceptual, Triangulated, Contested
                        Replication.</article-title>
                    <source>Clin Chem</source>.
                        <year>2017</year>;<volume>63</volume>(<issue>5</issue>):<fpage>943</fpage>&#x02013;<lpage>5</lpage>.
                    Epub 2017/03/17. <pub-id pub-id-type="doi">10.1373/clinchem.2017.271965</pub-id>
                        .<?supplied-pmid 28298413?><pub-id pub-id-type="pmid"
                    >28298413</pub-id></mixed-citation>
            </ref>
        </ref-list>
  
    </back>
</article>
